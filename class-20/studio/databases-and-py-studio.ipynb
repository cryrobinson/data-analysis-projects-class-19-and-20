{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "54326aff-51cd-4766-8046-828a92489c6d"
   },
   "source": [
    "# Studio: Working with Databases in Python\n",
    "\n",
    "For today's studio, we will be using the [TV Shows dataset](https://www.kaggle.com/ruchi798/tv-shows-on-netflix-prime-video-hulu-and-disney) from Kaggle. We have already downloaded the CSV for you.\n",
    "\n",
    "You will use the watchlist you created to answer these questions:\n",
    "\n",
    "1. **Which streaming services contain the shows you want to watch next?**\n",
    "2. **Which streaming service is the best value based on the shows you want to watch?**\n",
    "\n",
    "As you complete the different tasks in the studio, you may choose between using Pandas or SQL. \n",
    "\n",
    "**Remember**: we learned in our prep work that one is oftentimes more efficient at certain tasks than the other, so choose wisely!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "00bc62ef-6c46-40a2-bdad-a3250a003ce7"
   },
   "source": [
    "## My Watchlist\n",
    "\n",
    "If you would like, please use this space to make note of your watchlist by editing the text cell. You will need 10 shows overall.\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. \n",
    "6. \n",
    "7. \n",
    "8. \n",
    "9. \n",
    "10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "040bdac5-f7fc-474f-b112-1d807249ad0a"
   },
   "source": [
    "## Database Setup\n",
    "\n",
    "Import the necessary libraries and create a dataframe from the provided CSV. \n",
    "\n",
    "Print the info out for the dataframe. \n",
    "\n",
    "After that, you may drop the column called `Unnamed: 0` and rename any columns with spaces or unusual characters in the names such as `\"Disney+\"`. \n",
    "\n",
    "Print out the info for the dataframe again to ensure your changes were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "azdata_cell_guid": "965f15d3-27b1-43ed-97e4-8c6fd482476c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5368 entries, 0 to 5367\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0       5368 non-null   int64 \n",
      " 1   ID               5368 non-null   int64 \n",
      " 2   Title            5368 non-null   object\n",
      " 3   Year             5368 non-null   int64 \n",
      " 4   Age              3241 non-null   object\n",
      " 5   IMDb             4406 non-null   object\n",
      " 6   Rotten Tomatoes  5368 non-null   object\n",
      " 7   Netflix          5368 non-null   int64 \n",
      " 8   Hulu             5368 non-null   int64 \n",
      " 9   Prime Video      5368 non-null   int64 \n",
      " 10  Disney+          5368 non-null   int64 \n",
      " 11  Type             5368 non-null   int64 \n",
      "dtypes: int64(8), object(4)\n",
      "memory usage: 503.4+ KB\n",
      "None\n",
      "\n",
      "Updated DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5368 entries, 0 to 5367\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   ID               5368 non-null   int64 \n",
      " 1   Title            5368 non-null   object\n",
      " 2   Year             5368 non-null   int64 \n",
      " 3   Age              3241 non-null   object\n",
      " 4   IMDb             4406 non-null   object\n",
      " 5   Rotten_Tomatoes  5368 non-null   object\n",
      " 6   Netflix          5368 non-null   int64 \n",
      " 7   Hulu             5368 non-null   int64 \n",
      " 8   Prime_Video      5368 non-null   int64 \n",
      " 9   Disneyplus       5368 non-null   int64 \n",
      " 10  Type             5368 non-null   int64 \n",
      "dtypes: int64(7), object(4)\n",
      "memory usage: 461.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import sqlite3\n",
    "\n",
    "df = pd.read_csv(\"tv_shows.csv\")\n",
    "\n",
    "print(\"Initial DataFrame info:\")\n",
    "print(df.info())\n",
    "\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "df.columns = df.columns.str.replace(' ', '_').str.replace('+', 'plus')\n",
    "\n",
    "print(\"\\nUpdated DataFrame info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "93875e01-f1ec-45ab-b8b3-c0fe09c89c41"
   },
   "source": [
    "With your dataframe at the ready, create a new database called `tv.db`. \n",
    "\n",
    "Add a new table to your database called `shows` using the data in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "azdata_cell_guid": "cae4affc-d930-4649-9c39-551475a83b5b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been written to tv.db in the shows table.\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "conn = sqlite3.connect('tv.db')\n",
    "df.to_sql('shows', conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "\n",
    "print(\"DataFrame has been written to tv.db in the shows table.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "4916f211-149f-467b-b5e4-22ad946b54f2"
   },
   "source": [
    "With your new table and database set up, print out the top 20 records in the `shows`Â table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "azdata_cell_guid": "c6aa3980-3eef-4d7d-8f04-961508662147",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID                       Title  Year  Age    IMDb Rotten_Tomatoes  \\\n",
      "0    1                Breaking Bad  2008  18+  9.4/10         100/100   \n",
      "1    2             Stranger Things  2016  16+  8.7/10          96/100   \n",
      "2    3             Attack on Titan  2013  18+  9.0/10          95/100   \n",
      "3    4            Better Call Saul  2015  18+  8.8/10          94/100   \n",
      "4    5                        Dark  2017  16+  8.8/10          93/100   \n",
      "5    6  Avatar: The Last Airbender  2005   7+  9.3/10          93/100   \n",
      "6    7              Peaky Blinders  2013  18+  8.8/10          93/100   \n",
      "7    8            The Walking Dead  2010  18+  8.2/10          93/100   \n",
      "8    9                Black Mirror  2011  18+  8.8/10          92/100   \n",
      "9   10          The Queen's Gambit  2020  18+  8.6/10          92/100   \n",
      "10  11                  Mindhunter  2017  18+  8.6/10          90/100   \n",
      "11  12                   Community  2009   7+  8.5/10          90/100   \n",
      "12  13                      Narcos  2015  18+  8.8/10          90/100   \n",
      "13  14                   Shameless  2011  18+  8.5/10          90/100   \n",
      "14  15                 Money Heist  2017  18+  8.3/10          90/100   \n",
      "15  16          Marvel's Daredevil  2015  18+  8.6/10          90/100   \n",
      "16  17                     Lucifer  2016  16+  8.1/10          90/100   \n",
      "17  18                Supernatural  2005  16+  8.4/10          89/100   \n",
      "18  19                 The Witcher  2019  18+  8.2/10          89/100   \n",
      "19  20                       Ozark  2017  18+  8.4/10          89/100   \n",
      "\n",
      "    Netflix  Hulu  Prime_Video  Disneyplus  Type  \n",
      "0         1     0            0           0     1  \n",
      "1         1     0            0           0     1  \n",
      "2         1     1            0           0     1  \n",
      "3         1     0            0           0     1  \n",
      "4         1     0            0           0     1  \n",
      "5         1     0            1           0     1  \n",
      "6         1     0            0           0     1  \n",
      "7         1     0            0           0     1  \n",
      "8         1     0            0           0     1  \n",
      "9         1     0            0           0     1  \n",
      "10        1     0            0           0     1  \n",
      "11        1     1            1           0     1  \n",
      "12        1     0            0           0     1  \n",
      "13        1     1            1           0     1  \n",
      "14        1     0            0           0     1  \n",
      "15        1     0            0           0     1  \n",
      "16        1     0            0           0     1  \n",
      "17        1     0            0           0     1  \n",
      "18        1     0            0           0     1  \n",
      "19        1     0            0           0     1  \n"
     ]
    }
   ],
   "source": [
    "# Code Here\n",
    "conn = sqlite3.connect('tv.db')\n",
    "query = \"SELECT * FROM shows LIMIT 20;\"\n",
    "top_20_records = pd.read_sql_query(query, conn)\n",
    "\n",
    "print(top_20_records)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "f158ccd2-c87a-4d2c-a947-0eadd0484a3e"
   },
   "source": [
    "Now, create a new table called `watchlist` that has three fields:\n",
    "1. id -> data type of `INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT`\n",
    "2. title -> data type of `TEXT`\n",
    "3. importance_rank -> data type of `INTEGER`\n",
    "\n",
    "For the `importance_rank` field, rank each of your watchlist shows based on how much you want to see them, `10` being the most important and `1` being the least important.\n",
    "\n",
    "Then, insert each of the items from your watchlist into the new `watchlist` table, using the `executemany` method from our exercises.\n",
    "\n",
    "Finally, select all the records from the `watchlist` table and print them out to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "azdata_cell_guid": "f95defad-521b-4112-8435-08daaac80b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id   title  importance_rank\n",
      "0   1  Show A               10\n",
      "1   2  Show B                9\n",
      "2   3  Show C                8\n",
      "3   4  Show D                7\n",
      "4   5  Show E                6\n",
      "5   6  Show F                5\n",
      "6   7  Show G                4\n",
      "7   8  Show H                3\n",
      "8   9  Show I                2\n",
      "9  10  Show J                1\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "conn = sqlite3.connect('tv.db')\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS watchlist (\n",
    "    id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n",
    "    title TEXT,\n",
    "    importance_rank INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "conn.execute(create_table_query)\n",
    "\n",
    "watchlist_items = [\n",
    "    (\"Show A\", 10),\n",
    "    (\"Show B\", 9),\n",
    "    (\"Show C\", 8),\n",
    "    (\"Show D\", 7),\n",
    "    (\"Show E\", 6),\n",
    "    (\"Show F\", 5),\n",
    "    (\"Show G\", 4),\n",
    "    (\"Show H\", 3),\n",
    "    (\"Show I\", 2),\n",
    "    (\"Show J\", 1)\n",
    "]\n",
    "\n",
    "insert_query = \"INSERT INTO watchlist (title, importance_rank) VALUES (?, ?);\"\n",
    "conn.executemany(insert_query, watchlist_items)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "select_query = \"SELECT * FROM watchlist;\"\n",
    "watchlist_records = pd.read_sql_query(select_query, conn)\n",
    "\n",
    "print(watchlist_records)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "4716090d-63e3-4283-8245-934c4a28c750"
   },
   "source": [
    "## Working with the Data\n",
    "\n",
    "Using Pandas or SQL, find the answer to these 2 questions:\n",
    "1. How many of the total shows (full csv list) are on each streaming service?\n",
    "2. What percentage of these total shows is available on each streaming service?\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "Use the pandas `query` method to filter the data, and then the Python `len` method to find it's length. [Relevant Link](https://www.geeksforgeeks.org/ways-to-filter-pandas-dataframe-by-column-values/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "azdata_cell_guid": "8e4f3757-474f-4e20-b861-db973437b541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Streaming_Service  Count  Percentage\n",
      "0           Netflix   1971   36.717586\n",
      "1              Hulu   1621   30.197466\n",
      "2       Prime_Video   1831   34.109538\n",
      "3        Disneyplus    351    6.538748\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"tv_shows.csv\")\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df.columns = df.columns.str.replace(' ', '_').str.replace('+', 'plus')\n",
    "\n",
    "total_shows = len(df)\n",
    "streaming_counts = df[['Netflix', 'Hulu', 'Prime_Video', 'Disneyplus']].sum()\n",
    "streaming_percentages = (streaming_counts / total_shows) * 100\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Count': streaming_counts,\n",
    "    'Percentage': streaming_percentages\n",
    "}).reset_index()\n",
    "\n",
    "results.columns = ['Streaming_Service', 'Count', 'Percentage']\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "167cbd0d-ad9f-4f27-8066-e45dfdfaf421"
   },
   "source": [
    "\n",
    "Now join your `watchlist` data to the `shows` data using pandas or SQL. Verify that you joined the data correctly.\n",
    "\n",
    "Using this related dataset, come up with analytic code that answers these questions:\n",
    "1. The number of watchlist shows each streaming service has\n",
    "2. The percentage of your overall watchlist each streaming service has\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "azdata_cell_guid": "b871523e-a476-4f3a-a6ac-2e251f140e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watchlist DataFrame Columns:\n",
      "Index(['id', 'title', 'importance_rank'], dtype='object')\n",
      "Shows DataFrame Columns:\n",
      "Index(['ID', 'Title', 'Year', 'Age', 'IMDb', 'Rotten_Tomatoes', 'Netflix',\n",
      "       'Hulu', 'Prime_Video', 'Disneyplus', 'Type'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3q/89j1fbhn3535fsc60pr_c_xw0000gn/T/ipykernel_75583/42041189.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shows DataFrame Columns:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshows_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mjoined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwatchlist_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshows_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Joined DataFrame:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoined_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/LaunchCode/data-analysis-projects/venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10828\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10829\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10835\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/LaunchCode/data-analysis-projects/venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/LaunchCode/data-analysis-projects/venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/LaunchCode/data-analysis-projects/venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1306\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                         \u001b[0;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/LaunchCode/data-analysis-projects/venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Title'"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('tv.db')\n",
    "\n",
    "shows_df = pd.read_sql_query(\"SELECT * FROM shows;\", conn)\n",
    "watchlist_df = pd.read_sql_query(\"SELECT * FROM watchlist;\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(\"Watchlist DataFrame Columns:\")\n",
    "print(watchlist_df.columns)\n",
    "\n",
    "print(\"Shows DataFrame Columns:\")\n",
    "print(shows_df.columns)\n",
    "\n",
    "joined_df = watchlist_df.merge(shows_df, on='Title', how='inner')\n",
    "\n",
    "print(\"Joined DataFrame:\")\n",
    "print(joined_df.head())\n",
    "\n",
    "streaming_counts = joined_df[['Netflix', 'Hulu', 'Prime_Video', 'Disney+']].sum()\n",
    "total_watchlist_count = len(watchlist_df)\n",
    "watchlist_percentages = (streaming_counts / total_watchlist_count) * 100\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Count': streaming_counts,\n",
    "    'Percentage': watchlist_percentages\n",
    "}).reset_index()\n",
    "\n",
    "results.columns = ['Streaming_Service', 'Count', 'Percentage']\n",
    "\n",
    "# Print the results\n",
    "print(\"Watchlist Analysis:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "909689e4-1aae-41e3-b1f8-158ebe5ec3ca"
   },
   "source": [
    "## Results\n",
    "\n",
    "Now that you have done your analysis, make note of the answers to the following questions by editing the text cell:\n",
    "\n",
    "1. Was every show on your watchlist in the Kaggle dataset? Do you have any ideas as to why a show might not have been present?\n",
    "\n",
    "- *your_answer*\n",
    "\n",
    "2. Did you include a show or shows in your watchlist that is exclusive to one of the platforms? How might that have impacted your analysis?\n",
    "\n",
    "- *your_answer*\n",
    "\n",
    "3. Which streaming service(s) offered the most shows on your watchlist? Which streaming service(s) offered the least?\n",
    "\n",
    "- *your_answer*\n",
    "\n",
    "4. Based on the shows you want to watch and the results of your analysis, is there a streaming service you think would be a good fit for you?\n",
    "\n",
    "- *your_answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Mission\n",
    "\n",
    "We didn't end up using that `importance_rank` field, did we?\n",
    "\n",
    "Well, that was intentional! \n",
    "\n",
    "Your bonus mission is to come up with analysis that uses that field to determine, based on watchlist show importance_rank and number of watchlist shows available on a service, which platform you should subscribe to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
